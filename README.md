# Text-Analysis-Final-Project
Since the original files, text files after data cleaning and files containing the tokenized text are much larger than Github’s capacity of 25 MB, all of these files can be accessed in the Google Drive using LionMail. 

## Introduction
Censorship, the suppression of speech, public communication and other information, has significant implications on individuals’ freedom to speech in a country. As the Internet rapidly develops in the 21st century, social media becomes the major platform for individuals to share information and speak up. In China, one of the most influential social media platforms that boasts over 500 million registered users as of 2021 is called Sina Weibo. When the platform was first launched in 2009, the Chinese government praised it for enabling people to raise suggestions for the government on the platform. However, the censorship mechanism on Weibo became stronger over the past decade and created enormous fear for people to speak freely on the platform. 
This research intends to investigate how the censorship device operates on Weibo by looking at a database called Weiboscope that collects 111 censored posts in 2012 from Weibo. 
The major research question of this study is: what are the important keywords that trigger the censorship mechanism on Weibo?

## Hypothesis
Based on [previous qualitative and quantitative research](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2265271) and a variety of new reports,
Weibo tends to censor posts that contain politically sensitive content, especially “the posts that may lead to collective actions.” This can be translated into an intolerance of public criticism of the government. Therefore, this study hypothesized that the posts targeted by the Internet censorship machine contain keywords related to the government and public affairs such as “政府”(government), “国家”(nation), and “党”(party). Furthermore, this study expects that Weibo posts are more likely to be censored if they contain comments on international affairs. Thus it anticipates names of foreign countries as important keywords. 

## Data Collection
This project will analyze the data collected by a data collection system called *[Weiboscope]* (https://datahub.hku.hk/articles/dataset/Weiboscope_Open_Data/16674565), developed by the research team at the Journalism and Media Studies Centre, The University of Hong Kong (JMSC). The team made use of the Sina Weibo Open API to access the microblog data, and collect the censored posts by frequently revisiting the user’s timeline. The system collected 111 million Weibo posts between January 1, 2012 and June 30, 2012. 
Their sample is made up of three particular groups of microbloggers: 1) less than 10 China Media Project researchers at the University of Hong Kong, who are scholars and active writers on the China media industry. Group 1 users’ timeline was checked every 3 minutes 2) 5,000 users who are the friends of Group 1 users,  mostly Chinese dissident writers, journalists and scholars. The update for Group 2 is run every 6 hours. 3) authenticated VIP status users who have more than 10,000 followers, consist of about 38,000 users. Each update is run once a day for this group. The research team tracked the timelines of these microbloggers by comparing the recently modified timeline with the immediately previous timeline. If missing posts were detected through comparison, the research team will then analyze whether their absences are caused by censorship or voluntary deletion by looking at the API response (the former returns “permission denied”, and the latter returns “Weibo does not exist”). If a post was deleted voluntarily, they were excluded from the data collection to avoid contamination of the truly censored posts.
2-month period data (made up of data of 8 weeks) from Weiboscope’s open data website was downloaded in CSV file format for the purpose of this study, and it consists of around 8 million censored Weibo posts. These CSV files contain various information about the censored posts including time, images and so on. However, since Weibo texts are the only content needed to conduct analysis, this study only keeps the texts and saves them into new files (e.g.week1_clean..csv) before data cleaning and analysis. 


